- [字节后端日常实习一面](#字节后端日常实习一面)
  - [MySQL](#mysql)
    - [索引(结构，为什么使用B+树,失效的情况)](#索引结构为什么使用b树失效的情况)
    - [超大表分页](#超大表分页)
      - [问题分析](#问题分析)
      - [解决方案](#解决方案)
  - [redis](#redis)
    - [持久化(RDB, AOF介绍, 原理，使用场景)](#持久化rdb-aof介绍-原理使用场景)
      - [**Fork + COW 机制详细流程**](#fork--cow-机制详细流程)
    - [页表副本的准确理解](#页表副本的准确理解)
      - [1. Fork 时创建的是什么副本？](#1-fork-时创建的是什么副本)
      - [2. 页表项的详细结构](#2-页表项的详细结构)
      - [3. 页表如何指向不同位置](#3-页表如何指向不同位置)
      - [4. COW 过程中页表变化的详细过程](#4-cow-过程中页表变化的详细过程)
      - [5. Fork 前后页表状态对比](#5-fork-前后页表状态对比)
      - [6. 多级页表的复制](#6-多级页表的复制)
    - [关键要点总结](#关键要点总结)
  - [计算机网络](#计算机网络)
    - [tcp和http的区别](#tcp和http的区别)
    - [http1 2 3 的区别](#http1-2-3-的区别)
    - [tcp三次握手，最后一次没确认会发生什么？](#tcp三次握手最后一次没确认会发生什么)
  - [消息队列](#消息队列)
    - [kafka](#kafka)
      - [顺序消费](#顺序消费)
      - [高可用](#高可用)
      - [高性能](#高性能)
      - [isr和osr](#isr和osr)
      - [避免重复消费](#避免重复消费)
      - [rabbitmq 和 kafka的区别](#rabbitmq-和-kafka的区别)
  - [场景题：设计一个朋友圈系统](#场景题设计一个朋友圈系统)
  - [一、点赞功能设计思路 (使用 Redis)](#一点赞功能设计思路-使用-redis)
    - [1. Redis 数据结构选择：](#1-redis-数据结构选择)
    - [2. 配合持久化存储：](#2-配合持久化存储)
    - [3. 流程示例 (使用 Set + 单独计数器)：](#3-流程示例-使用-set--单独计数器)
  - [二、评论功能设计思路](#二评论功能设计思路)
    - [1. 持久化存储 (主要存储)：](#1-持久化存储-主要存储)
    - [2. Redis 用于评论的缓存和加速：](#2-redis-用于评论的缓存和加速)
    - [3. 评论内容（含图片）处理：](#3-评论内容含图片处理)
    - [4. 流程示例 (缓存最新评论列表)：](#4-流程示例-缓存最新评论列表)
  - [总结与注意事项：](#总结与注意事项)
  - [算法：lc(删除k个数字后使数字最小)](#算法lc删除k个数字后使数字最小)

# 字节后端日常实习一面
自我介绍，介绍实习项目，介绍自己的项目
挑一个自己熟悉的项目介绍

## MySQL
### 索引(结构，为什么使用B+树,失效的情况)
MySQL主要使用B+树作为索引结构，B+树的所有数据都在叶子节点上，非叶子节点只保存索引信息；
主要优点是支持范围查询，且B+树的高度较低，查询效率高。保存在叶子节点的方式使得B+树可以更好地支持范围查询和顺序访问。

索引失效的情况包括：
1. 使用了不支持索引的函数，如`SELECT * FROM table WHERE YEAR(date_column) = 2020`。
2. 对索引列进行了类型转换，如`SELECT * FROM table WHERE index_column + 1 = 5`。
3. 使用了`OR`连接多个条件，导致无法使用索引。为什么？因为`OR`会导致查询优化器选择全表扫描而不是使用索引。
4.  使用了模糊查询`LIKE '%value%'`，因为这种查询方式无法利用索引。
5.  最左前缀原则被破坏，如`WHERE column2 = value2 AND column1 = value1`，如果`column1`是索引的第一列，但查询条件中没有使用它。
6. 使用了函数或表达式对索引列进行操作，如`WHERE UPPER(column) = 'VALUE'`。为什么？因为函数或表达式会导致索引列的值被改变，无法直接使用索引。
7. 在`WHERE`子句中使用了不等于`<>`或`!=`运算符。为什么？因为这些运算符会导致查询优化器无法使用索引进行快速定位，而是需要扫描更多的行。哪些运算符不会导致索引失效？等于`=`、大于`>`、小于`<`、大于等于`>=`、小于等于`<=`等运算符通常不会导致索引失效，因为它们可以直接利用索引进行快速定位。
8. 在`WHERE`子句中使用了`NULL`值，如`WHERE column IS NULL`。为什么？因为`NULL`值在索引中通常被视为特殊值，可能导致查询优化器无法使用索引进行快速定位。
9. 在`ORDER BY`子句中使用了非索引列，如`ORDER BY non_indexed_column`。为什么？因为非索引列无法利用索引进行排序，可能导致全表扫描或临时表的创建。
10. 在`JOIN`操作中使用了非索引列，如`JOIN table2 ON table1.non_indexed_column = table2.non_indexed_column`。为什么？因为非索引列无法利用索引进行连接，可能导致全表扫描或临时表的创建。

### 超大表分页
深分页问题，如`SELECT * FROM table LIMIT 1000000, 10`，会导致性能问题，因为数据库需要扫描前1000000条记录才能返回结果。

#### 问题分析
1. **OFFSET性能问题**：随着OFFSET增大，查询时间呈线性增长
2. **内存占用**：需要加载大量数据到内存中
3. **锁竞争**：长时间查询可能导致锁等待

#### 解决方案

**1. 基于游标的分页（Keyset Pagination）**
```sql
-- 第一页
SELECT * FROM table WHERE id > 0 ORDER BY id LIMIT 10;

-- 下一页（假设上一页最后一条记录的id是100）
SELECT * FROM table WHERE id > 100 ORDER BY id LIMIT 10;
```
优点：性能稳定，不受页数影响
缺点：无法跳页，需要连续翻页

**2. 延迟关联（Deferred Join）**
```sql
-- 传统方式
SELECT * FROM table LIMIT 1000000, 10;

-- 优化后
SELECT t.* FROM table t 
INNER JOIN (
    SELECT id FROM table ORDER BY id LIMIT 1000000, 10
) temp ON t.id = temp.id;
```

**3. 使用覆盖索引**
```sql
-- 确保查询的列都在索引中
SELECT id, name FROM table ORDER BY id LIMIT 1000000, 10;
```

**4. 分片策略**
- **水平分片**：按时间、地区等维度分表
- **垂直分片**：按业务功能分表
- **使用分布式数据库**：如TiDB、ShardingSphere

**5. 缓存策略**
- **Redis缓存热点数据**
- **应用层缓存**：缓存常查询的分页结果
- **CDN缓存**：对于静态数据

**6. 搜索引擎方案**
- **Elasticsearch**：适合复杂查询和全文搜索
- **Solr**：适合结构化数据搜索

**7. 业务层优化**
- **禁止深度分页**：限制最大页数（如只允许前100页）
- **改变交互方式**：使用"加载更多"替代分页
- **提供过滤条件**：让用户缩小结果集

**8. 数据库层优化**
```sql
-- 使用COUNT优化
-- 避免 SELECT COUNT(*) FROM large_table
-- 改用预估值或缓存总数

-- 使用分区表
CREATE TABLE large_table (
    id INT,
    created_date DATE,
    ...
) PARTITION BY RANGE (YEAR(created_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025)
);
```

**9. 技术选型建议**
- **小于100万行**：普通LIMIT OFFSET可接受
- **100万-1000万行**：使用游标分页或延迟关联
- **超过1000万行**：考虑分片、搜索引擎或业务限制

**10. Go语言实现示例**
```go
// 游标分页实现
type CursorPagination struct {
    Cursor string `json:"cursor"`
    Limit  int    `json:"limit"`
}

func GetDataWithCursor(cursor string, limit int) ([]Data, string, error) {
    query := "SELECT * FROM table WHERE id > ? ORDER BY id LIMIT ?"
    // 执行查询...
    // 返回数据和下一个cursor
}
```

## redis
### 持久化(RDB, AOF介绍, 原理，使用场景)
RDB是快照持久化，是在指定时间间隔内将数据集快照保存到磁盘的方式。快照是将数据的二进制格式保存到磁盘上，适合于数据量较大且对实时性要求不高的场景。RDB的优点是恢复速度快，缺点是可能会丢失最近几分钟的数据。
AOF是追加文件持久化，是将每次写操作记录到日志文件中，适合于对数据一致性要求较高的场景。AOF的优点是可以保证数据的完整性，缺点是恢复速度较慢。
Redis支持三种持久化方式：RDB、AOF和混合持久化。混合持久化是将RDB和AOF结合起来使用，既可以保证数据的完整性，又可以提高恢复速度。
持久化过程中用到了`fsync`函数，`fsync`函数会将数据从内存刷新到磁盘，确保数据的持久化。Redis提供了三种`fsync`策略：
1. **每次写操作都fsync**：保证数据的完整性，但性能较差。
2. **每秒fsync一次**：性能较好，但可能会丢失最近一秒的数据。
3. **不fsync**：性能最好，但数据可能会丢失。
快照过程中会使用`fork`系统调用创建子进程，触发`fork`时，操作系统会使用写时复制（Copy-On-Write）技术，只有在子进程修改数据时才会复制数据，这样可以减少内存的使用。

#### **Fork + COW 机制详细流程**

> 1. Fork 系统调用阶段
> ``` 
> // 模拟场景：Redis 进行 RDB 持久化
> func createSnapshot() {
>     pid := syscall.Fork()
>
>     if pid == 0 {
>         // 子进程：执行快照保存
>         saveSnapshotToDisk()
>         os.Exit(0)
>     } else if pid > 0 {
>         // 父进程：继续处理请求
>         continueServingRequests()
>     }
> }
> ```
>  > **Fork 时发生的事情：**  
>  >创建新的进程控制块（PCB）  
>  >复制父进程的页表，但不复制实际的物理内存页  
>  >将所有内存页标记为只读  
>  >父子进程共享相同的物理内存页

1. 写时复制（COW）触发机制
初始状态（Fork后）:
````
┌─────────────┐    ┌─────────────┐
│  父进程     │    │  子进程       │
│  虚拟地址   │    │  虚拟地址     │
└─────────────┘    └─────────────┘
      │                   │
      └─────────┬─────────┘  
                │  
        ┌───────▼───────┐
        │  共享物理页   │
        │ (只读标记)    │
        └───────────────┘
````

3. 写操作触发复制
````写操作发生:
┌─────────────┐    ┌─────────────┐
│  父进程     │    │  子进程     │
│ 尝试写入A页 │    │            │
└─────────────┘    └─────────────┘
      │
      ▼
┌─────────────┐
│ 页面错误    │
│(Page Fault) │
└─────────────┘
      │
      ▼
┌─────────────┐    ┌─────────────┐
│  父进程     │    │  子进程     │
│  新A页副本  │    │  原A页      │
└─────────────┘    └─────────────┘
````

4. 内核处理 COW 页面错误
```
// 内核处理 COW 页面错误的伪代码
void handle_cow_fault(struct vm_area_struct *vma, unsigned long address) {
    struct page *old_page = get_page_from_address(address);
    
    if (page_count(old_page) == 1) {
        // 只有一个进程引用此页，直接标记为可写
        set_page_writable(old_page);
    } else {
        // 多个进程引用，需要复制
        struct page *new_page = alloc_page();
        copy_page_data(old_page, new_page);
        
        // 更新页表指向新页
        update_page_table(vma, address, new_page);
        set_page_writable(new_page);
        
        // 减少原页引用计数
        put_page(old_page);
    }
}
```

**COW 的优势和时间复杂度**  
内存使用优化：
无修改时：O(1) 内存使用，父子进程共享
有修改时：O(n) 内存使用，n 为修改的页数
时间复杂度：首次写入 O(1)（页面复制），后续写入 O(1)

```场景1：快照期间无写操作
内存使用：100% 共享，内存效率最高

场景2：快照期间有少量写操作  
内存使用：大部分共享 + 少量复制页

场景3：快照期间有大量写操作
内存使用：接近完全复制，效率降低
```

**关键要点总结**  
Fork 不立即复制内存：只复制页表结构  
COW 延迟复制：只在写操作时才复制特定页面  
内存标记：所有页面初始标记为只读  
页面错误驱动：通过页面错误机制触发复制  
引用计数：内核维护每个物理页的引用计数

### 页表副本的准确理解

#### 1. Fork 时创建的是什么副本？

````
Fork 操作创建的副本层次：

进程级别:
┌─────────────────┐    ┌─────────────────┐
│   父进程 PCB    │    │   子进程 PCB    │
│  - 进程ID       │    │  - 进程ID       │
│  - 页表指针     │    │  - 页表指针     │
└─────────────────┘    └─────────────────┘
         │                       │
         ▼                       ▼
┌─────────────────┐    ┌─────────────────┐
│   父进程页表    │    │   子进程页表    │
│ (页表结构副本)  │    │ (页表结构副本)  │
└─────────────────┘    └─────────────────┘
         │                       │
         └───────┬───────────────┘
                 ▼
       ┌─────────────────┐
       │   共享物理内存   │
       │     页面        │
       └─────────────────┘
````

**答案：是的，副本指的是页表结构的副本，而不是物理内存页的副本。**

#### 2. 页表项的详细结构

````go
// 页表项的基本结构（简化版）
type PageTableEntry struct {
    PhysicalFrameNumber uint64  // 指向物理内存帧号
    Present             bool    // 页面是否在内存中
    Writable            bool    // 是否可写
    UserAccessible      bool    // 用户态是否可访问
    WriteThrough        bool    // 写透模式
    CacheDisabled       bool    // 是否禁用缓存
    Accessed            bool    // 是否被访问过
    Dirty               bool    // 是否被修改过
    PageSize            bool    // 页面大小标志
    Global              bool    // 全局页面标志
    Available           uint8   // 可用位
}
````

#### 3. 页表如何指向不同位置

**是的，页表中的数据（页表项）可以指向不同的物理内存位置：**

````
虚拟内存布局示例：

虚拟地址空间:        页表项:              物理内存:
┌─────────────┐     ┌──────────────┐     ┌─────────────┐
│0x1000 (代码)│────→│PTE1: 0x5000  │────→│0x5000 页面  │
├─────────────┤     ├──────────────┤     ├─────────────┤
│0x2000 (数据)│────→│PTE2: 0x3000  │────→│0x3000 页面  │
├─────────────┤     ├──────────────┤     ├─────────────┤
│0x3000 (堆)  │────→│PTE3: 0x7000  │────→│0x7000 页面  │
└─────────────┘     └──────────────┘     └─────────────┘
````

#### 4. COW 过程中页表变化的详细过程

````go
// 模拟 COW 过程中页表的变化
type VirtualMemoryManager struct {
    pageTable map[uint64]*PageTableEntry
}

func (vmm *VirtualMemoryManager) handleCOWFault(virtualAddr uint64) {
    pte := vmm.pageTable[virtualAddr]
    oldPhysAddr := pte.PhysicalFrameNumber
    
    if vmm.getReferenceCount(oldPhysAddr) > 1 {
        // 需要复制页面
        newPhysAddr := vmm.allocateNewPage()
        vmm.copyPageContent(oldPhysAddr, newPhysAddr)
        
        // 更新页表项指向新的物理地址
        pte.PhysicalFrameNumber = newPhysAddr
        pte.Writable = true
        
        // 减少原物理页的引用计数
        vmm.decrementRefCount(oldPhysAddr)
        
        log.Printf("COW: 虚拟地址 0x%x 从物理地址 0x%x 重定向到 0x%x", 
                   virtualAddr, oldPhysAddr, newPhysAddr)
    } else {
        // 只有一个引用，直接标记为可写
        pte.Writable = true
    }
}
````

#### 5. Fork 前后页表状态对比

````
Fork 前 (父进程):
虚拟地址    页表项           物理地址
0x1000  →  [PTE: 0x5000]  →  0x5000 (可写)
0x2000  →  [PTE: 0x3000]  →  0x3000 (可写)

Fork 后 (父子进程都有相同的页表结构):
父进程页表:                    子进程页表:
虚拟地址    页表项             虚拟地址    页表项
0x1000  →  [PTE: 0x5000]  →   0x1000  →  [PTE: 0x5000]
0x2000  →  [PTE: 0x3000]  →   0x2000  →  [PTE: 0x3000]
           (只读标记)                    (只读标记)
               │                           │
               └─────────┬─────────────────┘
                         ▼
                  共享物理内存:
                  0x5000, 0x3000

写操作后 (父进程写入 0x1000):
父进程页表:                    子进程页表:
0x1000  →  [PTE: 0x8000]  →   0x1000  →  [PTE: 0x5000]
0x2000  →  [PTE: 0x3000]  →   0x2000  →  [PTE: 0x3000]
           (新分配的页)                   (原共享页)
````

#### 6. 多级页表的复制

````go
// 多级页表结构
type MultiLevelPageTable struct {
    PGD []PageGlobalDirectory  // 页全局目录
    PUD []PageUpperDirectory   // 页上级目录  
    PMD []PageMiddleDirectory  // 页中间目录
    PTE []PageTableEntry      // 页表项
}

func (mlpt *MultiLevelPageTable) forkPageTable() *MultiLevelPageTable {
    newPageTable := &MultiLevelPageTable{
        PGD: make([]PageGlobalDirectory, len(mlpt.PGD)),
        PUD: make([]PageUpperDirectory, len(mlpt.PUD)),
        PMD: make([]PageMiddleDirectory, len(mlpt.PMD)),
        PTE: make([]PageTableEntry, len(mlpt.PTE)),
    }
    
    // 复制所有级别的页表结构
    copy(newPageTable.PGD, mlpt.PGD)
    copy(newPageTable.PUD, mlpt.PUD)
    copy(newPageTable.PMD, mlpt.PMD)
    copy(newPageTable.PTE, mlpt.PTE)
    
    // 将所有页表项标记为只读（COW）
    for i := range newPageTable.PTE {
        newPageTable.PTE[i].Writable = false
        mlpt.PTE[i].Writable = false
    }
    
    return newPageTable
}
````

### 关键要点总结

1. **页表副本**：Fork 创建的是页表结构的完整副本，包括所有级别的页表
2. **指向灵活性**：页表项可以指向物理内存中的任意位置，这是虚拟内存的核心机制
3. **动态重定向**：COW 机制通过修改页表项的物理地址指向来实现内存的延迟复制
4. **引用计数**：内核维护每个物理页的引用计数来决定是否需要复制
5. **权限控制**：页表项中的权限位（如可写位）用于触发 COW 机制

这种设计使得虚拟内存系统既高效又灵活，是现代操作系统内存管理的基础。

## 计算机网络
### tcp和http的区别
tcp是传输控制协议处于传输层，提供可靠的、面向连接的字节流服务。它通过三次握手建立连接，保证数据的可靠传输，并且可以进行流量控制和拥塞控制。
http是超文本传输协议处于应用层，基于tcp协议之上，用于在客户端和服务器之间传输超文本数据。它是无状态的，每次请求都是独立的，不会保留之前的状态信息。通过http请求头和响应头传递元数据，如内容类型、缓存控制等。

### http1 2 3 的区别
HTTP/1.1是HTTP的第一个版本，使用文本协议，支持持久连接和管道化，但存在头部冗余和性能瓶颈问题。
HTTP/2引入了二进制协议，支持多路复用、头部压缩和服务器推送等特性，解决了HTTP/1.1的性能问题。它通过流的方式传输数据，可以在一个连接上同时发送多个请求和响应，减少了延迟。存在tcp的头部阻塞问题。
HTTP/3基于QUIC协议，使用UDP传输，解决了TCP的头部阻塞问题。QUIC在传输层实现了多路复用、流量控制和拥塞控制等功能，提供更低的延迟和更好的性能。HTTP/3还支持0-RTT连接建立，可以在第一次握手时就发送数据，进一步减少延迟。

### tcp三次握手，最后一次没确认会发生什么？
时间线分析：  
```
T0：客户端发送ACK(丢失)  
客户端状态：established  
服务端状态：SYN-RECEIVED

T1：服务端超时没有收到ack，重传SYN-ACK  
    服务端状态：SYN-RECEIVED

T1+：客户端收到重传的SYN-ACK，发送ACK确认；

T1++：服务器收到ACK  
服务器端状态：ESTABLISHED
```

**如果超过最大重试次数，服务端会关闭连接并释放资源。
清理资源，重新进入listen状态，等待新的连接请求。  
如果后面收到了之前连接的ACK，服务端会发送RST包，告知客户端连接已关闭。  
客户端收到RST包后，会关闭连接并释放资源。**

TCP三次握手的最后一次确认是为了确保双方都能接收到对方的连接请求。如果最后一次确认没有收到，发送方会在一定时间内重试发送SYN-ACK包，直到达到最大重试次数或超时。如果重试次数超过限制，连接将被认为失败，发送方会关闭连接并释放资源。

## 消息队列
### kafka
#### 顺序消费
Kafka通过分区（Partition）来实现顺序消费。每个分区内的消息是有序的，消费者可以按照分区顺序消费消息。  
Kafka保证同一分区内的消息在同一消费者组内是有序的，但不同分区之间的消息顺序是不保证的。*在一个消费者组中，同时只有一个消费者消费某个分区的消息，但是可以并行消费不同分区的消息。*
消费者可以通过指定分区来消费特定分区的消息，从而实现顺序消费。
#### 高可用
Kafka通过复制（Replication）来实现高可用。每个分区可以有多个副本（Replica），其中一个副本是Leader，其他副本是Follower。
Leader负责处理所有的读写请求，Follower从Leader同步数据。这样即使某个Broker宕机，其他Broker仍然可以提供服务，保证数据的高可用性。
#### 高性能
Kafka通过以下方式实现高性能：
1. **批量处理**：Kafka支持批量发送和接收消息，减少网络请求次数，提高吞吐量。
   - 生产者可以将多条消息打包成一个批次发送到Broker，减少网络开销。
   - 消费者可以批量拉取多条消息，减少网络请求次数。
2. **顺序写入**：Kafka将消息顺序写入磁盘，减少磁盘寻址时间，提高写入性能。
3. 顺序写入磁盘：Kafka将消息顺序写入磁盘，减少磁盘寻址时间，提高写入性能。
   - Kafka使用顺序写入的方式将数据写入日志文件，避免了随机写入带来的性能损失。
   - 顺序写入可以充分利用磁盘的带宽，提高数据写入速度。
4. **零拷贝技术**：Kafka使用零拷贝技术将数据从内存直接写入磁盘，减少数据复制，提高性能。
5.  **分区和并行处理**：Kafka将数据分区，可以在多个Broker上并行处理，提高吞吐量。
#### isr和osr
ISR（In-Sync Replica）是指与Leader副本保持同步的副本集合，只有ISR中的副本才能成为新的Leader。OSR（Out-Of-Sync Replica）是指与Leader副本不同步的副本，不能参与选举。  
高水位线（High Watermark）是指已提交的消息中，所有ISR副本都已确认的最高偏移量。只有在高水位线之前的消息才能被消费者消费。
#### 避免重复消费



#### rabbitmq 和 kafka的区别


## 场景题：设计一个朋友圈系统
有一个消息中心
上传图片，视频，文字等推送到用户白名单中；
用户接收到这些提醒后，刷新朋友圈加载内容；
点赞功能，用户可以对内容进行点赞，增加互动性。使用redis保存点赞信息？
评论怎么实现？使用redis保存评论信息，评论可以包含文本、图片等内容。

这两个功能是社交应用的核心，使用 Redis 确实能极大地提升性能和用户体验。下面是针对点赞和评论功能使用 Redis 的一些思路：

## 一、点赞功能设计思路 (使用 Redis)

点赞的核心需求是：快速记录谁对什么内容点了赞，快速取消点赞，以及快速获取点赞总数和判断某个用户是否点过赞。

### 1. Redis 数据结构选择：

*   **方案一：使用 Set (集合)**
    *   **键 (Key)**：`post:{post_id}:likes` (例如：`post:12345:likes`)
    *   **值 (Value)**：存储点赞用户的 `user_id` 集合。
    *   **操作**：
        *   **点赞**：`SADD post:{post_id}:likes {user_id}`
        *   **取消点赞**：`SREM post:{post_id}:likes {user_id}`
        *   **获取点赞总数**：`SCARD post:{post_id}:likes`
        *   **判断用户是否点赞**：`SISMEMBER post:{post_id}:likes {user_id}`
        *   **获取所有点赞用户**：`SMEMBERS post:{post_id}:likes` (注意：如果点赞数巨大，不建议直接获取所有，可能需要分页或只获取部分用于展示)
    *   **优点**：实现简单，语义清晰，能快速判断用户是否点赞和获取总数。
    *   **缺点**：无法记录点赞时间。

*   **方案二：使用 Sorted Set (有序集合)**
    *   **键 (Key)**：`post:{post_id}:likes_sorted`
    *   **成员 (Member)**：`user_id`
    *   **分数 (Score)**：点赞的时间戳 (timestamp)
    *   **操作**：
        *   **点赞**：`ZADD post:{post_id}:likes_sorted {timestamp} {user_id}`
        *   **取消点赞**：`ZREM post:{post_id}:likes_sorted {user_id}`
        *   **获取点赞总数**：`ZCARD post:{post_id}:likes_sorted`
        *   **判断用户是否点赞**：`ZSCORE post:{post_id}:likes_sorted {user_id}` (返回时间戳则表示已点赞)
        *   **获取按时间排序的点赞用户**：`ZRANGE` / `ZREVRANGE post:{post_id}:likes_sorted 0 9 WITHSCORES` (获取最新的10个点赞用户和时间)
    *   **优点**：可以按点赞时间排序，方便展示“XXX 等人刚刚赞过”。
    *   **缺点**：相比 Set 略微复杂一点。

*   **方案三：仅计数 (如果不需要知道谁点的赞，只关心总数)**
    *   **键 (Key)**：`post:{post_id}:like_count` (String 类型)
    *   **操作**：
        *   **点赞**：`INCR post:{post_id}:like_count`
        *   **取消点赞**：`DECR post:{post_id}:like_count` (需要确保取消点赞时该用户确实点过赞，否则计数会不准，通常配合方案一或方案二使用)
    *   **优点**：计数非常快。
    *   **缺点**：无法知道具体点赞用户。通常这个方案会和方案一或方案二结合，Set/Sorted Set 记录具体用户，String 类型单独快速维护总数。

### 2. 配合持久化存储：

*   Redis 中的点赞数据是热数据，用于快速读写。
*   **点赞记录应异步持久化到关系型数据库或 NoSQL 数据库中**，以防 Redis 数据丢失。
    *   数据库表设计：`likes (like_id PK, post_id, user_id, created_at, UNIQUE(post_id, user_id))`
*   可以使用消息队列（如 Kafka, RabbitMQ）将点赞/取消点赞操作异步写入数据库。

### 3. 流程示例 (使用 Set + 单独计数器)：

1.  **用户点赞 `post_id=123`, `user_id=789`**：
    *   `SADD post:123:likes 789` -> 返回1表示添加成功 (之前未点赞)
    *   如果上一步返回1，则 `INCR post:123:like_count`
    *   异步发送消息到队列，持久化该点赞记录到数据库。
2.  **用户取消点赞 `post_id=123`, `user_id=789`**：
    *   `SREM post:123:likes 789` -> 返回1表示移除成功 (之前已点赞)
    *   如果上一步返回1，则 `DECR post:123:like_count`
    *   异步发送消息到队列，从数据库删除或标记该点赞记录。

## 二、评论功能设计思路

评论数据通常包含较多文本，甚至图片链接，结构也可能更复杂（如楼中楼评论）。Redis 主要用于缓存热门评论、最新评论列表以及评论计数，**完整的评论数据应主要存储在持久化数据库中。**

### 1. 持久化存储 (主要存储)：

*   使用关系型数据库 (如 MySQL, PostgreSQL) 或文档数据库 (如 MongoDB)。
*   **表设计 (简化版)**：
    *   `comments (comment_id PK, post_id FK, user_id FK, content TEXT, image_urls JSON/TEXT, parent_comment_id FK NULL, created_at TIMESTAMP)`
    *   `parent_comment_id` 用于实现评论的层级关系。

### 2. Redis 用于评论的缓存和加速：

*   **方案一：缓存最新评论列表 (使用 List)**
    *   **键 (Key)**：`post:{post_id}:comments_latest`
    *   **值 (Value)**：存储 `comment_id` 或者序列化后的评论对象 JSON 字符串 (如果评论对象不大)。
    *   **操作**：
        *   **新评论发布**：
            1.  评论数据写入主数据库，获取 `comment_id`。
            2.  `LPUSH post:{post_id}:comments_latest {comment_id_or_serialized_comment}`
            3.  `LTRIM post:{post_id}:comments_latest 0 99` (例如，只保留最新的100条评论在缓存中)
        *   **获取最新评论**：
            1.  `LRANGE post:{post_id}:comments_latest 0 19` (获取最新的20条)
            2.  如果缓存中的是 `comment_id`，则根据 ID 批量从主数据库获取完整评论内容。
            3.  如果缓存中是序列化对象，直接反序列化使用。
    *   **优点**：简单高效地获取最新评论。
    *   **缺点**：不方便按热度等其他方式排序。

*   **方案二：缓存热门/精选评论列表 (使用 Sorted Set)**
    *   **键 (Key)**：`post:{post_id}:comments_hot`
    *   **成员 (Member)**：`comment_id` 或序列化评论对象。
    *   **分数 (Score)**：评论的热度分（例如：点赞数 + 回复数 * 权重 - 负面反馈等计算得出）。
    *   **操作**：
        *   **评论热度更新**：当评论被点赞、回复时，更新其在 Sorted Set 中的分数 `ZADD post:{post_id}:comments_hot {new_score} {comment_id}` (使用 `NX` 或 `XX` 选项按需更新)。
        *   **获取热门评论**：`ZREVRANGE post:{post_id}:comments_hot 0 9` (获取热度最高的10条)。
    *   **优点**：可以灵活展示热门评论。

*   **方案三：评论计数 (使用 String)**
    *   **键 (Key)**：`post:{post_id}:comment_count`
    *   **操作**：
        *   **新评论发布**：`INCR post:{post_id}:comment_count`
        *   **评论删除**：`DECR post:{post_id}:comment_count`
    *   **优点**：快速获取评论总数。

### 3. 评论内容（含图片）处理：

*   **文本内容**：存储在主数据库的 `content` 字段。
*   **图片内容**：
    1.  图片上传到专门的对象存储服务 (如 AWS S3, Aliyun OSS)。
    2.  在主数据库的 `image_urls` 字段中存储图片的 URL 列表。
    3.  Redis 缓存的序列化评论对象中可以包含这些图片 URL。

### 4. 流程示例 (缓存最新评论列表)：

1.  **用户发布评论到 `post_id=123`**：
    *   评论数据（文本、图片URL等）写入主数据库，获得 `comment_id=abc`。
    *   将 `comment_id=abc` (或序列化的评论对象) `LPUSH` 到 `post:123:comments_latest`。
    *   `LTRIM post:123:comments_latest 0 99`。
    *   `INCR post:123:comment_count`。
2.  **用户查看 `post_id=123` 的评论**：
    *   优先从 Redis `LRANGE post:123:comments_latest 0 19` 获取缓存的评论 ID 或对象。
    *   如果获取的是 ID，则根据 ID 从主数据库查询完整评论。
    *   如果需要加载更多（分页），则直接从主数据库按 `created_at` 倒序分页查询，并可以考虑将查询结果的部分数据回填到 Redis 缓存中（Cache-Aside 模式）。

## 总结与注意事项：

*   **数据一致性**：Redis 作为缓存，与主数据库之间可能存在短暂数据不一致。需要根据业务容忍度选择同步策略（如更新数据库后立即更新/失效 Redis 缓存）。
*   **内存管理**：Redis 是内存数据库，需要合理设置 Key 的过期时间，避免缓存过多冷数据。对于评论列表，`LTRIM` 是个好方法。
*   **原子性**：对于需要多个 Redis 命令组合的操作（如点赞并更新计数器），可以使用 Lua 脚本或 Redis Transaction (`MULTI`/`EXEC`) 来保证原子性。
*   **大Key问题**：如果一个帖子的点赞或评论非常多，对应的 Set 或 List 可能会非常大。需要监控并考虑是否需要拆分或限制。例如，对于点赞，如果只展示总数和部分点赞用户头像，就不需要把所有点赞用户都存在一个巨大的 Set 里长期缓存。
*   **图片等大内容**：Redis 不适合存储图片二进制这类大文件，应存储其元数据或 URL。

这些思路提供了一个起点，具体实现时还需要根据业务场景的细节进行调整和优化。

## 算法：lc(删除k个数字后使数字最小)

